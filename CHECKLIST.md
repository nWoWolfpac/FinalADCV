# UNet++ Project Checklist

## ‚úÖ Files ƒë√£ t·∫°o

### Core Implementation
- [x] `src/models/unetplusplus.py` - UNet++ model implementation
- [x] `src/models/encoder.py` - Pretrained encoder (ƒë√£ c√≥ s·∫µn)
- [x] `src/data/dataset_utils.py` - Dataset utilities (ƒë√£ c√≥ s·∫µn)
- [x] `src/utils.py` - Training utilities (ƒë√£ c·∫≠p nh·∫≠t)

### Training Scripts
- [x] `training_unetpp.py` - Main training script cho UNet++
- [x] `config.py` - Configuration file (ƒë√£ c√≥ s·∫µn)

### Experiment Tools
- [x] `run_experiments.sh` - Bash script ƒë·ªÉ ch·∫°y nhi·ªÅu experiments (Linux/Mac)
- [x] `run_experiments.bat` - Batch script ƒë·ªÉ ch·∫°y nhi·ªÅu experiments (Windows)
- [x] `compare_results.py` - Script so s√°nh k·∫øt qu·∫£ experiments

### Documentation
- [x] `README.md` - Main README
- [x] `README_UNETPP.md` - Chi ti·∫øt v·ªÅ UNet++
- [x] `QUICKSTART.md` - Quick start guide
- [x] `project-summary-doc.md` - Project overview (ƒë√£ c·∫≠p nh·∫≠t)
- [x] `CHECKLIST.md` - File n√†y

## üìã Tr∆∞·ªõc khi train

### 1. Ki·ªÉm tra m√¥i tr∆∞·ªùng
```bash
# Ki·ªÉm tra Python
python --version  # >= 3.8

# Ki·ªÉm tra PyTorch
python -c "import torch; print(torch.__version__)"

# Ki·ªÉm tra CUDA (n·∫øu d√πng GPU)
python -c "import torch; print(torch.cuda.is_available())"
```

### 2. C√†i ƒë·∫∑t dependencies
```bash
pip install torch torchvision
pip install transformers datasets
pip install matplotlib numpy tqdm pandas
```

### 3. Chu·∫©n b·ªã dataset
- [ ] Download DFC2020 dataset
- [ ] Gi·∫£i n√©n dataset
- [ ] C·∫≠p nh·∫≠t ƒë∆∞·ªùng d·∫´n trong `config.py`

```python
# config.py
STAGE2 = {
    "dataset_path": "path/to/dfc2020",  # ‚Üê C·∫≠p nh·∫≠t ƒë∆∞·ªùng d·∫´n n√†y
    ...
}
```

### 4. (Optional) Chu·∫©n b·ªã pretrained encoder
- [ ] Train encoder ·ªü Stage-1 (ho·∫∑c d√πng pretrained t·ª´ HuggingFace)
- [ ] L∆∞u encoder weights
- [ ] Ghi nh·ªõ ƒë∆∞·ªùng d·∫´n ƒë·ªÉ d√πng v·ªõi `--encoder_checkpoint`

## üöÄ Training Workflow

### Ch·ªçn m√¥i tr∆∞·ªùng training:

**Option A: Local**
```bash
python training_unetpp.py --backbone resnet50
```

**Option B: Cadence (Cloud GPU)** ‚òÅÔ∏è
1. M·ªü PyCharm
2. Ch·ªçn run configuration "Train UNet++ ResNet50"
3. Click "Run on Cadence"
4. Ch·ªçn GPU v√† Start

üìñ Chi ti·∫øt: `CADENCE_GUIDE.md`

### B∆∞·ªõc 1: Baseline
```bash
python training_unetpp.py --backbone resnet50
```
- [ ] Ch·∫°y th√†nh c√¥ng
- [ ] Ki·ªÉm tra output trong `checkpoints_unetpp_resnet50/`
- [ ] Xem `train_history.csv`

### B∆∞·ªõc 2: Deep Supervision
```bash
python training_unetpp.py --backbone resnet50 --deep_supervision --visualize
```
- [ ] Ch·∫°y th√†nh c√¥ng
- [ ] So s√°nh v·ªõi baseline
- [ ] Ki·ªÉm tra visualizations

### B∆∞·ªõc 3: Th·ª≠ backbone kh√°c
```bash
# MobileViT (nhanh)
python training_unetpp.py --backbone mobilevit --deep_supervision

# ResNet101 (ch√≠nh x√°c)
python training_unetpp.py --backbone resnet101 --deep_supervision
```
- [ ] Ch·∫°y v·ªõi MobileViT
- [ ] Ch·∫°y v·ªõi ResNet101
- [ ] So s√°nh k·∫øt qu·∫£

### B∆∞·ªõc 4: Experiments
```bash
# Ch·∫°y t·∫•t c·∫£ experiments
bash run_experiments.sh  # ho·∫∑c run_experiments.bat

# So s√°nh k·∫øt qu·∫£
python compare_results.py
```
- [ ] Ch·∫°y experiments
- [ ] Xem comparison plots
- [ ] Ch·ªçn best model

## üìä Sau khi train

### 1. Ki·ªÉm tra k·∫øt qu·∫£
- [ ] Xem `train_history.csv`
- [ ] Ki·ªÉm tra best mIoU
- [ ] Ki·ªÉm tra pixel accuracy
- [ ] Xem visualizations

### 2. So s√°nh experiments
- [ ] Ch·∫°y `compare_results.py`
- [ ] Xem `comparison_results/summary.csv`
- [ ] Xem comparison plots
- [ ] Ch·ªçn best configuration

### 3. ƒê√°nh gi√° model
- [ ] Load best checkpoint
- [ ] Test tr√™n test set
- [ ] T√≠nh metrics chi ti·∫øt
- [ ] Visualize predictions

## üêõ Troubleshooting Checklist

### Out of Memory
- [ ] Gi·∫£m batch_size trong config.py
- [ ] Gi·∫£m input_size trong config.py
- [ ] D√πng backbone nh·∫π h∆°n (mobilevit)
- [ ] T·∫Øt deep supervision
- [ ] Gi·∫£m num_workers

### Model kh√¥ng h·ªôi t·ª•
- [ ] Ki·ªÉm tra learning rate
- [ ] Ki·ªÉm tra data normalization
- [ ] B·∫≠t deep supervision
- [ ] Ki·ªÉm tra encoder c√≥ load ƒë√∫ng kh√¥ng
- [ ] TƒÉng s·ªë epochs

### Accuracy th·∫•p
- [ ] B·∫≠t deep supervision
- [ ] D√πng backbone m·∫°nh h∆°n
- [ ] D√πng pretrained encoder
- [ ] TƒÉng s·ªë epochs
- [ ] Ki·ªÉm tra class imbalance
- [ ] Th·ª≠ data augmentation

### Training ch·∫≠m
- [ ] TƒÉng batch size
- [ ] D√πng backbone nh·∫π h∆°n
- [ ] Gi·∫£m input size
- [ ] T·∫Øt deep supervision
- [ ] B·∫≠t mixed precision
- [ ] Gi·∫£m num_workers n·∫øu CPU bottleneck

## üìù Notes

### Best Practices
- ‚úÖ Lu√¥n d√πng pretrained encoder t·ª´ Stage-1
- ‚úÖ B·∫≠t deep supervision cho accuracy t·ªët h∆°n
- ‚úÖ Monitor c·∫£ loss v√† mIoU
- ‚úÖ Visualize predictions ƒë·ªÉ debug
- ‚úÖ Save training history
- ‚úÖ Compare multiple experiments

### Recommended Settings
```python
# config.py - Recommended for most cases
STAGE2 = {
    "batch_size": 16,           # Gi·∫£m n·∫øu OOM
    "num_epochs": 50,           # TƒÉng n·∫øu c·∫ßn
    "encoder_lr": 1e-5,         # Th·∫•p h∆°n decoder
    "decoder_lr": 1e-4,         # Cao h∆°n encoder
    "weight_decay": 1e-4,
    "input_size": 224,
    "mixed_precision": True,    # TƒÉng t·ªëc training
}
```

### Experiment Tracking
T·∫°o b·∫£ng ƒë·ªÉ track experiments:

| Exp | Backbone | Deep Sup | Best mIoU | Best Acc | Notes |
|-----|----------|----------|-----------|----------|-------|
| 1   | resnet50 | No       |           |          |       |
| 2   | resnet50 | Yes      |           |          |       |
| 3   | mobilevit| Yes      |           |          |       |
| 4   | resnet101| Yes      |           |          |       |

## üéØ Goals

### Minimum Goals
- [ ] Train UNet++ th√†nh c√¥ng
- [ ] ƒê·∫°t mIoU > 0.5
- [ ] Generate visualizations

### Target Goals
- [ ] So s√°nh √≠t nh·∫•t 3 backbones
- [ ] ƒê·∫°t mIoU > 0.6
- [ ] Deep supervision improve accuracy

### Stretch Goals
- [ ] ƒê·∫°t mIoU > 0.7
- [ ] Optimize inference speed
- [ ] Export model to ONNX

## ‚ú® Ho√†n th√†nh!

Khi ƒë√£ ho√†n th√†nh t·∫•t c·∫£:
- [ ] C√≥ best model v·ªõi mIoU cao
- [ ] C√≥ comparison results
- [ ] C√≥ visualizations
- [ ] Hi·ªÉu r√µ tradeoffs gi·ªØa c√°c backbones
- [ ] Document k·∫øt qu·∫£

---

**Good luck! üöÄ**
